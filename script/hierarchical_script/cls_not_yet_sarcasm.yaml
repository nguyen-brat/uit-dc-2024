data_args:
  train_data:
    annotate_paths: [
      "data/public_train/image_text_reasoning/train_image_text_ocr_llm_reasoning_v2.json",
      "data/public_train/image_text_reasoning/train_image_umsaple_x6_image_text_ocr_llm_reasoning_v2.json",
      "data/public_train/image_text_reasoning/train_text_umsaple_x10_image_text_ocr_llm_reasoning_v2.json",
    ]
    image_path: "data/public_train/train-images"
  val_data:
    annotate_paths: ["data/public_train/image_text_reasoning/test_image_text_ocr_llm_reasoning_v2.json"]
    image_path: "data/public_train/train-images"
  max_length: 2500
  labels_map:
    multi-sarcasm: 0
    not-sarcasm: 1
    image-sarcasm: 0
    text-sarcasm: 0
  inver_labels_map:
    "0": "multi-sarcasm"
    "1": "not-sarcasm"
  # min_pixels: 200704
  # max_pixels: 1003520
  # cache_dir: "./data_cache"

training_args:
  freeze_base: False
  bf16: True
  use_lora: True
  learning_rate: 5e-5
  lr_scheduler_type: "cosine"
  warmup_ratio: 0.1
  weight_decay: 0.0
  gradient_checkpointing: true
  gradient_checkpointing_kwargs: {"use_reentrant": False}
  save_safetensors: False
  torch_compile_backend: "cudagraphs"
  use_liger_kernel: False # BUG if True
  quantization: 0 # 0 mean not use quantization 4 mean 4 bit 8 mean 8 bit
  output_dir: "model/hierarchical/cls_multi_not_sarcasm_draft_image_text_reasoning_v2"
  overwrite_output_dir: true
  num_train_epochs: 4
  per_device_train_batch_size: 1
  per_device_eval_batch_size: 1
  gradient_accumulation_steps: 32
  dataloader_num_workers: 36
  do_train: true
  do_eval: true
  eval_strategy: "steps" # Evaluation is done (and logged) every eval_steps
  logging_strategy: "steps"
  save_strategy: "steps"
  eval_steps: 20
  save_steps: 20
  save_total_limit: 2
  # seed: null
  label_names: ["labels"]
  resume_from_checkpoint: False
  load_best_model_at_end: True
  prediction_loss_only: False
  metric_for_best_model: "f1"
  neftune_noise_alpha: 5
  # label_smoothing_factor: 0.1
  # optim: "paged_lion_8bit"

model_args:
  base_model: "LLaMA-Factory/models/sarcasm_detection_draft_reasoning_v2"
  extra_layers: 4
  model_kwargs:
      token: "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"
      use_cache: False
      attn_implementation: "flash_attention_2" # flash_attention_2, sdpa, eager
  attn_implementation: "flash_attention_2"

tokenizer_args:
  cache_dir: "./tokenizer_data"
  token: "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"

lora_args:
  use_dora: False
  r: 16
  lora_alpha: 32
  lora_dropout: 0.05
  bias: "none"
  target_modules: [
    .*\.down_proj,  # Add $ to match end of string
    .*\.gate_proj,
    .*\.v_proj,
    .*\.up_proj,
    .*\.k_proj,
    .*\.o_proj,
    .*\.q_proj
  ] # "all-linear"
  modules_to_save: [
    ^encoder_layers.*,  # Add ^ to match start of string
    ^classification_layer
  ]

wandb_args:
  run_name: "cls_multi_not_sarcasm_draft_image_text_reasoning_v2" # "My goodfellas"
  logging_steps: 1
  report_to: "wandb"

callback_args:
  patient: null

huggingface_args:
  push_to_hub: false
  hub_private_repo: true
  hub_model_id: "qwen2vl7b-cls"
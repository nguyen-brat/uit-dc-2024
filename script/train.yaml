data_args:
  train_data:
    annotate_path: "data/public_train/ocr_llm_fix.json"
    image_path: "data/public_train/train-images"
  val_data:
    annotate_path: "data/warn_up/ocr_llm.json"
    image_path: "data/warn_up/warmup-images"
  max_length: 2500
  # min_pixels: 200704
  # max_pixels: 1003520
  # cache_dir: "./data_cache"

training_args:
  freeze_base: False
  bf16: True
  use_lora: True
  learning_rate: 5e-5
  lr_scheduler_type: "cosine"
  warmup_ratio: 0.1
  weight_decay: 0.0
  gradient_checkpointing: true
  gradient_checkpointing_kwargs: {"use_reentrant": False}
  save_safetensors: False
  torch_compile_backend: "cudagraphs"
  use_liger_kernel: False # BUG if True
  quantization: 0 # 0 mean not use quantization 4 mean 4 bit 8 mean 8 bit
  output_dir: "qwen2_vl_qwen2_reason_cls"
  overwrite_output_dir: true
  num_train_epochs: 3
  per_device_train_batch_size: 2
  per_device_eval_batch_size: 2
  gradient_accumulation_steps: 8
  dataloader_num_workers: 36
  do_train: true
  do_eval: true
  eval_strategy: "steps" # Evaluation is done (and logged) every eval_steps
  logging_strategy: "steps"
  save_strategy: "steps"
  eval_steps: 30
  save_steps: 150
  save_total_limit: 5
  # seed: null
  label_names: ["labels"]
  resume_from_checkpoint: False
  load_best_model_at_end: True
  prediction_loss_only: False
  metric_for_best_model: "f1"

model_args:
  base_model: "Qwen/Qwen2-VL-7B-Instruct"
  extra_layers: 0
  num_class: 4
  model_kwargs:
      token: "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"
      use_cache: False
      attn_implementation: "flash_attention_2" # flash_attention_2, sdpa, eager
  attn_implementation: "flash_attention_2"

tokenizer_args:
  cache_dir: "./tokenizer_data"
  token: "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"

lora_args:
  use_dora: False
  r: 16
  lora_alpha: 32
  lora_dropout: 0.05
  bias: "none"
  target_modules: ['down_proj','gate_proj','v_proj','up_proj','k_proj','o_proj','q_proj'] # "all-linear"
  modules_to_save: ["encoder_layers.*", "classification_layer"]

wandb_args:
  run_name: "freeze hill" # "My goodfellas"
  logging_steps: 1
  report_to: "wandb"

callback_args:
  patient: 3

huggingface_args:
  push_to_hub: false
  hub_private_repo: true
  hub_model_id: "qwen2vl7b-cls"
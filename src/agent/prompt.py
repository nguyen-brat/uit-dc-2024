from transformers import Qwen2VLProcessor, AutoProcessor, PreTrainedTokenizer
from qwen_vl_utils import process_vision_info
import json
from PIL import Image
from typing import List
from utils import *


SYSTEM_PROMPT_EN = '''You are a helpful assistant. Answer in English proper. Imagine you are a Vietnamese content moderator on Vietnam facebook post you need to reasoning \
to category the content of the post (contain an image and a caption) is multi-sarcasm, not-sarcasm, image-sarcasm or text-sarcasm.'''


# multi-sarcasm sample
FEW_SHOT_IMAGE_1 = "data/warn_up/warmup-images/75c2dd020173567a242ad1d2f1bd774844832dd2fab51d0663b2d7f58afbc88e.jpg"
FEW_SHOT_CAPTION_1 = '''Given the content of a facebook post with image above, Caption and OCR (text in image) below contain Sarcasm meaning:
### Caption:
may m√† g·∫∑p ƒë∆∞·ª£c t√¥i

### OCR (text in the image)
TR·ªúI ∆†I. L√ÄM SAO TH·∫æ N√ÄY \nc·∫≠u B·∫†N N√ÄY ƒêANG V·∫º D·ªû TH√å LƒÇN ƒê√ôNG RA co GI·∫¨T S√ôI B·ªåT M√âP:\nNGUY QU√Å: ƒê·ªÄ T√îI GI√öP.'''
FEW_SHOT_REASONING_1 = '''

### Reasoning
Step 1: Describe the image
This image is a three-panel comic strip featuring three characters. The first character is a person with yellow helmet. \
The second character is a blue, round bird with a single eye and a small hat. \
The third character has white hair wearing red pant purpple T-shirt.
In the first panel, the person exclaims, "Tr·ªùi ∆°i! L√†m sao th·∫ø n√†y?!" and try to helping someone. The blue bird is passing towards the two person.
In the second panel, there a drawing on the easel, which appears to be a tiger. The yellow helmet person holding white hair person. \
The person yellow helmet person says, "C·∫≠u b·∫°n n√†y ƒëang v·∫Ω d·ªü th√¨ lƒÉn ƒë√πng ra co gi·∫≠t s√πi b·ªçt m√©p".\
The blue bird responds, "Nguy qu√°! ƒê·ªÉ t√¥i gi√∫p!" (Dangerous! Let me help!).
In the third panel, the blue bird is standing in front of the easel, looking at the drawing, while the person looks on with a concerned expression.

Step 2: Give argument then conclude one or more of these (image, OCR or the Caption) contain on or more facts in ### Sarcasm-signal
The character in the second pannel is falling in the floor and need help but when the blue bird run toward the two person,\
we expect the blue bird will help the white hair person which appear more emergency but the blue bird just go there and help drawing the unfinish picture. The Sarcasm signal appear is:\
2. the normaly expect the the blue bird will help white hair person but the blue bird help finish the picture. -> Contains a mismatch between the text and the image that suggests sarcasm through contradiction or exaggeration.
5. the Caption show out the blue bird will help the white hair person but at the end it not help. -> Characters whose actions are absurd and different from what is normally expected.

Step 3: Conclude whether the image, OCR and Caption contain Sarcasm or not-Sarcasm base on evaluation on step 2.
Both image, text in image and Caption contain Sarcasm.
'''

# not-sarcasm sample
FEW_SHOT_IMAGE_2 = "data/warn_up/warmup-images/2e1c147650933097225e804223a966d26c91bc5a92dc600961ed59027d359446.jpg"
FEW_SHOT_CAPTION_2 = '''Given the content of a facebook post with image above, Caption and OCR (text in image) below contain Sarcasm meaning:

### Caption:
S∆°n T√πng M-TP t·∫°i Ph·ªë ƒëi b·ªô mang c·∫£ \"xe vali g·∫•u b√¥ng\" t·∫∑ng kh√°n gi·∫£ ‚ô•Ô∏è‚ô•Ô∏è‚ô•Ô∏è

### OCR (text in the image)
Kh√¥ng c√≥ vƒÉn b·∫£n hay ch·ªØ trong ·∫£nh'''

FEW_SHOT_REASONING_2 = '''

### Reasoning
Step 1: Describe the image
The picture shows a person walking on a runway during a fashion show. The individual is wearing a black top with sheer sleeves and red leather pants. \
They are holding a fur accessory in one hand and have a confident posture. The background is dark, with a spotlight illuminating the model, creating a dramatic effect.

Step 2: Give argument then conclude one or more of these (image, OCR or the Caption) contain on or more facts in ### not-Sarcasm-signal
The Caption and image to notify a event organized by a celebrity. The not-Sarcasm signal appear is:
1. The Caption are straightforward to meaning that notify a event organized by a celebrity (S∆°n T√πng M-TP) giveaway to his audiences teddy bears -> Conveys sentiments or statements that are straightforward and meant to be taken at face value.
2. The Caption mention about S∆°n T√πng M-TP and the image also show the picture of him. -> Aligns directly with the image, supporting the literal interpretation of the text.
3. There is not trolling icon or image in the picture, Caption and OCR text -> Does NOT contain linguistic or visual cues typically associated with sarcasm.

Step 3: Conclude whether the image, OCR and Caption contain Sarcasm or not-Sarcasm base on evaluation on step 2.
Both image and ###Caption not contain Sarcasm.'''

SIGNAL = '''Suggest some sarcasm signal and not-sarcasm signal
### Sarcasm-signal
Given Sarcasm is any sample that contains one or more signs in the story (containing text and image) given below:
1. Employs irony by saying the opposite of what is meant, especially to mock or deride. \
Made in order to hurt someone's feelings, criticize or express something in a humorous way
2. Contains a mismatch between the text (in Caption or OCR) and the image that suggests sarcasm through contradiction or exaggeration.
3. Uses hyperbole to overstate or understate reality in a way that is clearly not meant to be taken literally
4. Incorporates sarcastic hashtags, emojis, or punctuation, which are commonly used to convey sarcasm online. \
Text in Caption or image that is not a conversation but put inside \"\" usually to sarcasm or say opposition thing.
5. Characters whose actions are absurd and different from what is normally expected.

### not-Sarcasm-signal
Given not-Sarcasm is any samples that contain one or more signs in the story (contain text and image) given below:
1. Conveys sentiments or statements that are straightforward and meant to be taken at face value.
2. Aligns directly with the image, supporting the literal interpretation of the text.
3. Does NOT contain linguistic or visual cues typically associated with sarcasm.
'''

REASONING_INS_EN = '''### Sarcasm-signal
Given Sarcasm is any sample that contains one or more signs in the story (containing text and image) given below:
1. Employs irony by saying the opposite of what is meant, especially to mock or deride. \
Made in order to hurt someone's feelings, criticize or express something in a humorous way
2. Contains a mismatch between the text (in Caption or OCR) and the image that suggests sarcasm through contradiction or exaggeration.
3. Uses hyperbole to overstate or understate reality in a way that is clearly not meant to be taken literally
4. Incorporates sarcastic hashtags, emojis, or punctuation, which are commonly used to convey sarcasm online. \
Text in Caption or image that is not a conversation but put inside \"\" usually to sarcasm or say opposition thing.
5. Characters whose actions are absurd and different from what is normally expected.

### not-Sarcasm-signal
Given not-Sarcasm is any samples that contain one or more signs in the story (contain text and image) given below:
1. Conveys sentiments or statements that are straightforward and meant to be taken at face value.
2. Aligns directly with the image, supporting the literal interpretation of the text.
3. Does NOT contain linguistic or visual cues typically associated with sarcasm.

### Instruction
Reasoning why this Vietnamese Facebook post contains {multi_label} meaning based on the definition of Sarcasm and not-Sarcasm given above. \
The sample given will be in order:
### Image

### Caption

### OCR (text in the image)

### Reasoning

Do step-by-step:
Step 1: Describe the picture.
Step 2: Give an argument then conclude image, OCR or the Caption contain {label} meaning based on ### {label}-signal given above
Step 3: Conclude whether the image, OCR, and Caption contain Sarcasm or not-Sarcasm based on evaluation in step 2.'''


TRAIN_USER_INS = '''Imagine you are a content moderator on facebook you need to reasoning \
to category the content of the post (contain an image and a caption) is multi-sarcasm, not-sarcasm, image-sarcasm or text-sarcasm. \
Suggest some sarcasm signal and not-sarcasm :

### Sarcasm-signal
Given Sarcasm is any sample that contains one or more signs in the story (containing text and image) given below:
1. Employs irony by saying the opposite of what is meant, especially to mock or deride. \
Made in order to hurt someone's feelings, criticize or express something in a humorous way
2. Contains a mismatch between the text (in Caption or OCR) and the image that suggests sarcasm through contradiction or exaggeration.
3. Uses hyperbole to overstate or understate reality in a way that is clearly not meant to be taken literally
4. Incorporates sarcastic hashtags, emojis, or punctuation, which are commonly used to convey sarcasm online. \
Text in Caption or image that is not a conversation but put inside \"\" usually to sarcasm or say opposition thing.
5. Characters whose actions are absurd and different from what is normally expected.

### not-Sarcasm-signal
Given not-Sarcasm is any samples that contain one or more signs in the story (contain text and image) given below:
1. Conveys sentiments or statements that are straightforward and meant to be taken at face value.
2. Aligns directly with the image, supporting the literal interpretation of the text.
3. Does NOT contain linguistic or visual cues typically associated with sarcasm.

Given a Facebook post contains an image <image>, the reference text in the image is: {ocr} and a caption: {caption}. \
Explain step-by-step by analysis the image and caption then give the conclusion that is post have multi-sarcasm, not-sarcasm, image-sarcasm or text-sarcasm meaning. The post is classified as:
- text-sarcasm: if only the content in the caption is sarcastic and the photo and text in the photo are not sarcastic or supportive and have the opposite meaning of the caption.
- image-sarcasm: if the photo or content in the photo contains signs of sarcasm, criticism, belittling or making fun of someone and the caption provided does not contain any signs of sarcasm and has all the elements of not-sarcasm.
- multi-sarcasm: if both the caption and the photo of the post contain elements of sarcasm or the caption supports the semantics of the photo's sarcasm, which can be text in the photo and vice versa.
- not-sarcasm: if both the caption and the photo do not contain signs of sarcasm as provided above. The post has a clear meaning without sarcasm and has the signs of not-sarcasm provided above.'''

TRAIN_SYS_RESPONSE = '''{reason}

**Final-result**
The post is -> {label}'''

VI_REASONING_INSTRUCTION = '<image>\nCho b√†i ƒëƒÉng tr√™n facebook g·ªìm b·ª©c ·∫£nh ƒë∆∞·ª£c cung c·∫•p v·ªõi d√≤ng caption: {caption}. B√†i ƒëƒÉng tr√™n c√≥ mang t√≠nh ch√¢m bi·∫øm kh√¥ng v√† gi·∫£i th√≠ch l√≠ do?'
VI_REASONING_INSTRUCTION_IMAGE = '<image>\nCho b√†i ƒëƒÉng tr√™n facebook. N·ªôi dung b·ª©c ·∫£nh bao g·ªìm ch·ªØ trong ·∫£nh c√≥ mang t√≠nh ch√¢m bi·∫øm kh√¥ng v√† v√¨ sao?'

from PIL import Image

def create_reas_prompt_qwen2_vl(
        processor:Qwen2VLProcessor,
        image_paths,
        captions,
        labels,
        ocrs,
):
    MAP = {
        "multi-sarcasm": "multi-sarcasm",
        "text-sarcasm": "text-sarcasm",
        "image-sarcasm": "image-sarcasm",
        "not-sarcasm": "not-Sarcasm",
    }
#     message = [
#         {"role": "system", "content": SYSTEM_PROMPT_EN},
#         # {
#         #     "role": "user",
#         #     "content": [
#         #         {"type": "text", "text": REASONING_INS_EN.format(multi_label="multi-sarcasm", label="Sarcasm")},
#         #         {"type": "image", "image": FEW_SHOT_IMAGE_1},
#         #         {"type": "text", "text": FEW_SHOT_CAPTION_1}
#         #     ]
#         # },
#         # {"role": "assistant", "content": FEW_SHOT_REASONING_1},
#         # {
#         #     "role": "user",
#         #     "content": [
#         #         {"type": "text", "text": REASONING_INS_EN.format(multi_label="not-Sarcasm", label="not-Sarcasm")},
#         #         {"type": "image", "image": FEW_SHOT_IMAGE_2},
#         #         {"type": "text", "text": FEW_SHOT_CAPTION_2},
#         #     ]
#         # },
#         # {"role": "assistant", "content": FEW_SHOT_REASONING_2},
#         {
#             "role": "user",
#             "content": [
#                 {"type": "text", "text": REASONING_INS_EN.format(multi_label=label, label=MAP[label])},
#                 {"type": "image", "image": image_path},
#                 {"type": "text", "text": f'''Given the content of a facebook post with image above, Caption and OCR (text in image) below contain {label} meaning step-by-step:
# ### Caption:
# {caption}

# ### OCR (text in image)
# {ocr}'''},
#             ]
#         }
#     ]

    messages = [
            [
            {"role": "system", "content": SYSTEM_PROMPT_EN},
            {
                "role": "user",
                "content": [
                    {"type": "text", "text":SIGNAL},
                    {"type": "image", "image": image_path},
                    {"type": "text", "text": f'''Given a Facebook post contains an image below and a caption: {caption}. The text in the image is: {ocr}. Explain step-by-step why this post contain {label} meaning ?'''},
                ]
            }
        ] for image_path, caption, ocr, label in zip(image_paths, captions, ocrs, labels)
    ]


    texts = [
        processor.apply_chat_template(
            message,
            tokenize=False,
            add_generation_prompt=True
        ) for message in messages
    ]
    

    image_inputs, video_inputs = process_vision_info(messages)

    inputs = processor(
        text=texts,
        images=image_inputs,
        videos=video_inputs,
        padding=True,
        return_tensors="pt",
    )
    return inputs


def create_reas_prompt_pixtral(
        processor,
        image_paths:List[str],
        captions,
        labels,
        ocrs,
):
    # message = [
    #     {"role": "system", "content": SYSTEM_PROMPT_EN},
        # {
        #     "role": "user",
        #     "content": [
        #         {"type": "text", "content": REASONING_INS_EN.format(multi_label="multi-sarcasm", label="Sarcasm")},
        #         {"type": "image"},
        #         {"type": "text", "content": FEW_SHOT_CAPTION_1}
        #     ]
        # },
        # {"role": "assistant", "content": FEW_SHOT_REASONING_1},
        # {
        #     "role": "user",
        #     "content": [
        #         {"type": "text", "content": REASONING_INS_EN.format(multi_label="not-Sarcasm", label="not-Sarcasm")},
        #         {"type": "image"},
        #         {"type": "text", "content": FEW_SHOT_CAPTION_2},
        #     ]
        # },
        # {"role": "assistant", "content": FEW_SHOT_REASONING_2},
#         {
#             "role": "user",
#             "content": [
#                 {"type": "text", "content": REASONING_INS_EN.format(multi_label=label, label=MAP[label])},
#                 {"type": "image"},
#                 {"type": "text", "content": f'''Given the content of a facebook post with image above, Caption and OCR (text in image) below contain {label} meaning:
# ### Caption:
# {caption}

# ### OCR (text in image)
# {ocr}'''},
#             ]
#         }
#     ]


    messages = [
        [
            {"role": "system", "content": SYSTEM_PROMPT_EN},
            {
                "role": "user",
                "content": [
                    {"type": "text", "content":SIGNAL},
                    {"type": "image"},
                    {"type": "text", "content": f"Given a Facebook post contains an image above and a caption: {caption}. The text in the image is: {ocr}. Explain step-by-step why this post contain {label} meaning ?"},
                ]
            }
        ] for caption, ocr, label in zip(captions, ocrs, labels)
    ]

    # inputs = processor(text=prompt, images=[Image.open(FEW_SHOT_IMAGE_1), Image.open(FEW_SHOT_IMAGE_2), Image.open(image_path)], return_tensors="pt")
    prompts = [processor.apply_chat_template(message) for message in messages]
    inputs = processor(
        text=prompts,
        images=[[Image.open(image_path)] for image_path in image_paths],
        return_tensors="pt",
        padding=True,
        padding_side="left",
    )
    return inputs


def create_vi_intern_prompt(
        tokenizer:PreTrainedTokenizer,
        image_paths:List[str],
        captions:List[str],
        labels:List[str],
        ocrs:List[str],
):
    pixel_values = load_image(image_paths[0], max_num=6).to(torch.bfloat16).cuda()
    question = VI_REASONING_INSTRUCTION.format(caption=captions[0])
    return dict(
        tokenizer=tokenizer,
        pixel_values=pixel_values,
        question=question
    )


def create_vi_intern_prompt_image(
        tokenizer:PreTrainedTokenizer,
        image_paths:List[str],
        captions:List[str],
        labels:List[str],
        ocrs:List[str],
):
    pixel_values = load_image(image_paths[0], max_num=6).to(torch.bfloat16).cuda()
    question = VI_REASONING_INSTRUCTION_IMAGE
    return dict(
        tokenizer=tokenizer,
        pixel_values=pixel_values,
        question=question
    )


if __name__ == "__main__":
    # from transformers import Qwen2VLForConditionalGeneration

    # processor = Qwen2VLProcessor.from_pretrained("Qwen/Qwen2-VL-7B-Instruct")
    # model = Qwen2VLForConditionalGeneration.from_pretrained(
    #     "Qwen/Qwen2-VL-7B-Instruct", torch_dtype="auto", device_map="auto"
    # )

    # inputs = create_reas_prompt_qwen2_vl(
    #     processor,
    #     "data/warn_up/warmup-images/bc24654fb4fba69b41b6b4dce15295fc4acc8ebce9b9bff452ef6a8890e04e72.jpg",
    #     "No shjt Sherlock",
    #     "multi-sarcasm",
    #     "Ti·ªÅn Phong - 2 gi·ªù\nPh√°t hi·ªán hai x√°c ch·∫øt trong nghƒ©a trang",
    # ).to(model.device)

    # inputs = create_reas_prompt_qwen2_vl(
    #     processor,
    #     "data/warn_up/warmup-images/a24d92ad80a7598313c1ce08769160cb2a3f9a18b06af0fe40e3aeca71c508e3.jpg",
    #     "Kh√¥ng bi·∫øt n√≥i ti·∫øng Anh th√¨ b·∫£o ng∆∞·ªùi ta n√≥i ti·∫øng Vi·ªát, th·∫ø m√† tr∆∞·ªõc gi·ªù kh√¥ng nghƒ© ra",
    #     "multi-sarcasm",
    #     "M√ä C√ÅCH NG·ªåC TRINH GIAO TI·∫æP V·ªöI TRAI T√ÇY: \"EM NGHƒ® L√Ä T·ªêT NH·∫§T ANH N√äN N√ìI TI·∫æNG VI·ªÜT ƒêI HA, N√ìI M·ªòT H·ªíI L√Ä EM KH√îNG HI·ªÇU G√å H·∫æT\"",
    # ).to(model.device)

    # inputs = create_reas_prompt_qwen2_vl(
    #     processor,
    #     "data/warn_up/warmup-images/34bbe4d8a417117023762ca6a80c11879e7823cd41f72a78863fe8a2623cda95.jpg",
    #     "Vi·ªát Nam, map game sinh t·ªìn kh√≥ nh·∫•t th·∫ø gi·ªõi.\n-The Deep",
    #     "multi-sarcasm",
    #     "B·ª©c ·∫£nh l√† m·ªôt trang web c·ªßa b√°o Ng∆∞·ªùi Lao ƒê·ªông v·ªõi ti√™u ƒë·ªÅ \"NG∆Ø·ªúI LAO ƒê·ªòNG\" ƒë∆∞·ª£c in ƒë·∫≠m v√† c·ª° ch·ªØ l·ªõn ·ªü ƒë·∫ßu trang. B√™n d∆∞·ªõi ti√™u ƒë·ªÅ l√† thanh menu v·ªõi c√°c m·ª•c: \"TRONG N∆Ø·ªöC\", \"QU·ªêC T·∫æ\", \"C√îNG ƒêO√ÄN\", \"BAN ƒê·ªåC\", \"KINH T·∫æ\", \"S·ª®C KH·ªéE\", \"GI√ÅO D·ª§C\", \"PH√ÅP LU·∫¨T\". Ti·∫øp theo l√† ph·∫ßn n·ªôi dung b√†i vi·∫øt v·ªõi ti√™u ƒë·ªÅ \"Ch√™ nh·∫°c \"d·ªü ec\", b·ªã ƒë√¢m v√†o ch·ªó hi·ªÉm ƒë·∫øn ch·∫øt!\" ƒë∆∞·ª£c in ƒë·∫≠m v√† c·ª° ch·ªØ l·ªõn. D∆∞·ªõi ti√™u ƒë·ªÅ l√† th√¥ng tin v·ªÅ th·ªùi gian ƒëƒÉng t·∫£i b√†i vi·∫øt: \"19-01-2013 - 11:07 | Ph√°p lu·∫≠t\". Ph·∫ßn n·ªôi dung b√†i vi·∫øt ƒë∆∞·ª£c chia th√†nh nhi·ªÅu ƒëo·∫°n vƒÉn, m·ªói ƒëo·∫°n ƒë∆∞·ª£c ƒë√°nh d·∫•u b·∫±ng d·∫•u g·∫°ch ngang. N·ªôi dung b√†i vi·∫øt xoay quanh v·ª• vi·ªác m·ªôt ng∆∞·ªùi ƒë√†n √¥ng t√™n V√µ H√πng H·∫≠u (SN 1986, ng·ª• qu·∫≠n 3) ƒë√£ b·ªã C√¥ng an qu·∫≠n 3-TPHCM b·∫Øt kh·∫©n c·∫•p do c√≥ h√†nh vi gi·∫øt √¥ng Nguy·ªÖn ƒê√¥ng Ph∆∞∆°ng (SN 1957, ng·ª• ph∆∞·ªùng 4, qu·∫≠n 3). Tr∆∞·ªõc ƒë√≥, √¥ng Ph∆∞∆°ng sang nh√† H·∫≠u ch∆°i. H·∫≠u ƒëang treo b·∫°c ƒë·ªÉ d·ªçn h√†ng b√°n v√† c√≥ m·ªü nh·∫°c x·∫≠p x√¨nh. √îng Ph∆∞∆°ng nh·∫≠n x√©t: \"Nh·∫°c d·ªü ec m√† c≈©ng nghe, ƒë√£ v·∫≠y c√≤n m·ªü l·ªõn n·ªØa\". Nghe v·∫≠y, H·∫≠u l·ªõn ti·∫øng ch·ª≠i l·∫°i √¥ng Ph∆∞∆°ng r·ªìi c·∫£ hai x·∫£y ra ·∫©u ƒë·∫£. Trong l√∫c n√≥ng gi·∫≠n, H·∫≠u ch·ª•p c√¢y k√©o g·∫ßn ƒë√≥ ƒë√¢m nhi·ªÅu nh√°t khi·∫øn √¥ng Ph∆∞∆°ng g·ª•c t·∫°i ch·ªó. Th·∫•y √¥ng Ph∆∞∆°ng b·ªã ƒë√¢m, m·ªôt s·ªë ng∆∞·ªùi nh√†o v√¥ can th√¨ c≈©ng b·ªã H·∫≠u g√¢y th∆∞∆°ng t√≠ch.",
    # ).to(model.device)

    # inputs = create_reas_prompt_qwen2_vl(
    #     processor,
    #     [
    #         "data/public_train/train-images/2b144cb2df4021574d73d82b20a2a5d86e8a11433a6c0fe7617ce0b67a868be1.jpg",
    #         #"data/public_train/train-images/f9a506b8dc0b5e770c31e327a85915a57112772c4966e7a0e77b0974e86b8dcf.jpg",
    #     ],
    #     [
    #         "Ch√∫c g√¨ k√¨ v·∫≠y ü§£",
    #         #"Cu·ªôc s·ªëng l√†m m·∫π l√† v·ª£ c·ªßa ng∆∞·ªùi ph·ª• n·ªØ g√≥i tr·ªçn trong 1 b·ª©c ·∫£nh",
    #     ],
    #     [
    #         "image-sarcasm", 
    #         #"not-sarcasm", 
    #         # "image-sarcasm", "not-sarcasm", "image-sarcasm", "not-sarcasm",
    #     ],
    #     [
    #         "Tr√≠ch xu·∫•t vƒÉn b·∫£n c√≥ trong ·∫£nh:\n- Tr·∫£ l·ªùi b√¨nh lu·∫≠n c·ªßa phantran1609\n- t·ªôi ch·ªã gh√™, ch√∫c ch·ªã s·ªõm m·ªçc l·∫°i ch√¢n nha\n- @T√∫ Linh\n- Tr·∫£ l·ªùi\n- @phantran1609\n- c·∫Øt ch√¢n r·ªìi sao m·ªçc ra ƒë∆∞·ª£c n·ªØa e kaka, ch√∫c mn ng√†y m... Xem th√™m\n- Linh √Çm thanh G·ªëc\n- @T√∫ L",
    #         #"Kh√¥ng c√≥ vƒÉn b·∫£n n√†o ƒë∆∞·ª£c tr√≠ch xu·∫•t t·ª´ h√¨nh ·∫£nh n√†y.",
    #     ],
    # ).to(model.device)


    # generated_ids = model.generate(**inputs, max_new_tokens=1024#, temperature=0.2, top_k=2, top_p=0.2, repetition_penalty=1
    #                                )
    # generated_ids_trimmed = [
    #     out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)
    # ]
    # output_text = processor.batch_decode(
    #     generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False
    # )
    # print(output_text[0])
    # print("================")
    # print(output_text[1])


    from transformers import AutoProcessor, LlavaForConditionalGeneration
    from PIL import Image
    import torch

    model_id = "mistral-community/pixtral-12b"
    processor = AutoProcessor.from_pretrained(model_id)
    processor.tokenizer.add_special_tokens({'pad_token': '<pad>'})
    model = LlavaForConditionalGeneration.from_pretrained(
        model_id,
        device_map="auto",
        # attn_implementation="flash_attention_2",
        torch_dtype=torch.bfloat16,
        low_cpu_mem_usage=True
    ).eval()

    # inputs = create_reas_prompt_pixtral(
    #     processor,
    #     "data/warn_up/warmup-images/bc24654fb4fba69b41b6b4dce15295fc4acc8ebce9b9bff452ef6a8890e04e72.jpg",
    #     "No shjt Sherlock",
    #     "multi-sarcasm",
    #     "Ti·ªÅn Phong - 2 gi·ªù\nPh√°t hi·ªán hai x√°c ch·∫øt trong nghƒ©a trang",
    # ).to(model.device)

    # inputs = create_reas_prompt_pixtral(
    #     processor,
    #     "data/warn_up/warmup-images/a24d92ad80a7598313c1ce08769160cb2a3f9a18b06af0fe40e3aeca71c508e3.jpg",
    #     "Kh√¥ng bi·∫øt n√≥i ti·∫øng Anh th√¨ b·∫£o ng∆∞·ªùi ta n√≥i ti·∫øng Vi·ªát, th·∫ø m√† tr∆∞·ªõc gi·ªù kh√¥ng nghƒ© ra",
    #     "multi-sarcasm",
    #     "M√ä C√ÅCH NG·ªåC TRINH GIAO TI·∫æP V·ªöI TRAI T√ÇY: \"EM NGHƒ® L√Ä T·ªêT NH·∫§T ANH N√äN N√ìI TI·∫æNG VI·ªÜT ƒêI HA, N√ìI M·ªòT H·ªíI L√Ä EM KH√îNG HI·ªÇU G√å H·∫æT\"",
    # ).to(model.device)

    # inputs = create_reas_prompt_pixtral(
    #     processor,
    #     "data/warn_up/warmup-images/34bbe4d8a417117023762ca6a80c11879e7823cd41f72a78863fe8a2623cda95.jpg",
    #     "Vi·ªát Nam, map game sinh t·ªìn kh√≥ nh·∫•t th·∫ø gi·ªõi.\n-The Deep",
    #     "multi-sarcasm",
    #     "B·ª©c ·∫£nh l√† m·ªôt trang web c·ªßa b√°o Ng∆∞·ªùi Lao ƒê·ªông v·ªõi ti√™u ƒë·ªÅ \"NG∆Ø·ªúI LAO ƒê·ªòNG\" ƒë∆∞·ª£c in ƒë·∫≠m v√† c·ª° ch·ªØ l·ªõn ·ªü ƒë·∫ßu trang. B√™n d∆∞·ªõi ti√™u ƒë·ªÅ l√† thanh menu v·ªõi c√°c m·ª•c: \"TRONG N∆Ø·ªöC\", \"QU·ªêC T·∫æ\", \"C√îNG ƒêO√ÄN\", \"BAN ƒê·ªåC\", \"KINH T·∫æ\", \"S·ª®C KH·ªéE\", \"GI√ÅO D·ª§C\", \"PH√ÅP LU·∫¨T\". Ti·∫øp theo l√† ph·∫ßn n·ªôi dung b√†i vi·∫øt v·ªõi ti√™u ƒë·ªÅ \"Ch√™ nh·∫°c \"d·ªü ec\", b·ªã ƒë√¢m v√†o ch·ªó hi·ªÉm ƒë·∫øn ch·∫øt!\" ƒë∆∞·ª£c in ƒë·∫≠m v√† c·ª° ch·ªØ l·ªõn. D∆∞·ªõi ti√™u ƒë·ªÅ l√† th√¥ng tin v·ªÅ th·ªùi gian ƒëƒÉng t·∫£i b√†i vi·∫øt: \"19-01-2013 - 11:07 | Ph√°p lu·∫≠t\". Ph·∫ßn n·ªôi dung b√†i vi·∫øt ƒë∆∞·ª£c chia th√†nh nhi·ªÅu ƒëo·∫°n vƒÉn, m·ªói ƒëo·∫°n ƒë∆∞·ª£c ƒë√°nh d·∫•u b·∫±ng d·∫•u g·∫°ch ngang. N·ªôi dung b√†i vi·∫øt xoay quanh v·ª• vi·ªác m·ªôt ng∆∞·ªùi ƒë√†n √¥ng t√™n V√µ H√πng H·∫≠u (SN 1986, ng·ª• qu·∫≠n 3) ƒë√£ b·ªã C√¥ng an qu·∫≠n 3-TPHCM b·∫Øt kh·∫©n c·∫•p do c√≥ h√†nh vi gi·∫øt √¥ng Nguy·ªÖn ƒê√¥ng Ph∆∞∆°ng (SN 1957, ng·ª• ph∆∞·ªùng 4, qu·∫≠n 3). Tr∆∞·ªõc ƒë√≥, √¥ng Ph∆∞∆°ng sang nh√† H·∫≠u ch∆°i. H·∫≠u ƒëang treo b·∫°c ƒë·ªÉ d·ªçn h√†ng b√°n v√† c√≥ m·ªü nh·∫°c x·∫≠p x√¨nh. √îng Ph∆∞∆°ng nh·∫≠n x√©t: \"Nh·∫°c d·ªü ec m√† c≈©ng nghe, ƒë√£ v·∫≠y c√≤n m·ªü l·ªõn n·ªØa\". Nghe v·∫≠y, H·∫≠u l·ªõn ti·∫øng ch·ª≠i l·∫°i √¥ng Ph∆∞∆°ng r·ªìi c·∫£ hai x·∫£y ra ·∫©u ƒë·∫£. Trong l√∫c n√≥ng gi·∫≠n, H·∫≠u ch·ª•p c√¢y k√©o g·∫ßn ƒë√≥ ƒë√¢m nhi·ªÅu nh√°t khi·∫øn √¥ng Ph∆∞∆°ng g·ª•c t·∫°i ch·ªó. Th·∫•y √¥ng Ph∆∞∆°ng b·ªã ƒë√¢m, m·ªôt s·ªë ng∆∞·ªùi nh√†o v√¥ can th√¨ c≈©ng b·ªã H·∫≠u g√¢y th∆∞∆°ng t√≠ch.",
    # ).to(model.device)

    inputs = create_reas_prompt_pixtral(
        processor,
        [
            "data/public_train/train-images/2b144cb2df4021574d73d82b20a2a5d86e8a11433a6c0fe7617ce0b67a868be1.jpg",
            "data/public_train/train-images/f9a506b8dc0b5e770c31e327a85915a57112772c4966e7a0e77b0974e86b8dcf.jpg"
        ],
        [
            "Ch√∫c g√¨ k√¨ v·∫≠y ü§£",
            "Cu·ªôc s·ªëng l√†m m·∫π l√† v·ª£ c·ªßa ng∆∞·ªùi ph·ª• n·ªØ g√≥i tr·ªçn trong 1 b·ª©c ·∫£nh",
        ],
        [
            "image-sarcasm",
            "not-sarcasm"
        ],
        [
            "Tr√≠ch xu·∫•t vƒÉn b·∫£n c√≥ trong ·∫£nh:\n- Tr·∫£ l·ªùi b√¨nh lu·∫≠n c·ªßa phantran1609\n- t·ªôi ch·ªã gh√™, ch√∫c ch·ªã s·ªõm m·ªçc l·∫°i ch√¢n nha\n- @T√∫ Linh\n- Tr·∫£ l·ªùi\n- @phantran1609\n- c·∫Øt ch√¢n r·ªìi sao m·ªçc ra ƒë∆∞·ª£c n·ªØa e kaka, ch√∫c mn ng√†y m... Xem th√™m\n- Linh √Çm thanh G·ªëc\n- @T√∫ L",
            "Kh√¥ng c√≥ vƒÉn b·∫£n n√†o ƒë∆∞·ª£c tr√≠ch xu·∫•t t·ª´ h√¨nh ·∫£nh n√†y."
        ],
    ).to(model.device)


    with torch.no_grad():
        generate_ids = model.generate(**inputs, max_new_tokens=500, repetition_penalty= 1.0, temperature= 0.1, top_p=0.005, top_k= 1,)

    generated_ids_trimmed = [
        out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generate_ids)
    ]
    output_text = processor.batch_decode(
        generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False
    )
    print(output_text[0])
    print("==========================")
    print(output_text[1])